---
title: "Case Study: MovieMagic Concessions and User Review Statistical Analysis"
author: "Brian Burdick, Chris Gearheart and Chris Porter"

output:
  html_document: default
  pdf_document: default
---
```{r setup, include= FALSE}
# Install Libraries
library(tidyverse)
#library(dplyr)
library(psycho)
library(car)
library(caret)
library(knitr)
library(caTools)
library(glmnet)
#library(tidyverse)
library(topicmodels)
#library(ggplot2)
#library(dplyr)
#library(tidytext)
#library(tidyr)
library(RTextTools)
library(wordcloud)
library(tm)
#library(stringr)
library(reshape2)
#library(tidyverse)
library(topicmodels)
#library(ggplot2)
#library(dplyr)
library(tidytext)
#library(tidyr)
library(RTextTools)
library(wordcloud)
library(tm)
#library(stringr)


# Load project data
data <- read.csv("http://data.mishra.us/files/project_data.csv")
#datasplit <- createDataPartition(data$amount_spent, p = 0.7, list=FALSE)
#trainData <- data[datasplit,]
#testData <- data[-datasplit,]
#text <- read.csv(url("http://data.mishra.us/files/project_reviews.csv"))
```

##  Introduction

*MovieMagic*, is a regional movie chain operating in the Southwest region of the US.  They are considering ways in which they can
increase spending on concessions. MovieMagic has collected information about 2000 of its customers, some of whom are part of their loyalty program and some who are not. They have information on 8 variables, which they plan to use as predictors. They plan to use the amount spent on concessions as the outcome variable
since they have learned from observation that much of their profit is derived from concession sales.

**Regression Analysis**


```{r linear regression, warning=FALSE, message=FALSE}
#head(data)
model1<- lm(amount_spent~., data=data)
summary(model1) # will give output for each level of each categorical predictor

#model2 <- aov(amount_spent~., data = data)
#summary(model2)

```
Based upon linear regression analysis, we are able to identify age, streaming, days_member and movies_seen as the significant predictors (p <0.05) of amount spent on concessions.  <!--Upon eliminating non-significant predictor variables, we see that the model continues to explain a similar amount of the variation (MRS 0.6738 -> 0.635), so little loss of information has occurred. -->

```{r LM refinement, warning=FALSE, message=FALSE, include=FALSE}
modelLM<- lm(amount_spent~age+streaming+days_member+movies_seen, data= data)
summary(modelLM)

```
Of the signficant independent variables, *age*, *days_member* and *movies_seen* all display a positive influence on the outcome variable *amount_spent* meaning that for every increase in these variables, it is predicted that the amount spent on concession will also increase.  The only significant predictor variable to display a negative influence is *streaming* which shows a remarkably strong negative influence when compared with the other predictor variables.  Therefore any increase in this variable will strongly decrease the *amount_spent* outcome variable.  This was determined using a linear regression. To determine whether a penalized regression analysis would further inform this, we need to determine to what extent the independent variables are correlated.  As with any data set of seemingly independent variables, the possibility exists that the independent variables are not in fact independent.  To determine this we check for multicollinearity.

*Multicollinear Analysis*

The primary test for mulitcollinearity is to calculate the Variance Inflation Factor (VIF) for each independent variable.

```{r VIF, warning=FALSE, message=FALSE}
vif(model1)
#vif(modelLM)
```
None of the variables display a high degree of multicollinearity (VIF > 5).  As such, no measures are required to address multicollinearity in the model.


## Strategies to increase concessions spending

Q3. Given the significant predictors, MovieMagic's management can ??? to increase the amount spent on concessions.

The statistically significant variables and their direction are `age` (higher age means higher sales), quantity of `streaming` subscriptions held by customer (more subscriptions means lower sales), `days member` (veteran MovieMagic members spend more on concessions), and `movies_seen` during the last time period (more movies seen correlates to higher sales).

These variables suggest a demographic story about MovieMagic's most profitable customers. The chain's cash cows are likely middle-aged or senior movie buffs who have, for whatever reason, not imitated young consumers' tendency to join multiple on-demand media platforms despite the wider movie selection the platforms offer. These customers also enjoy MovieMagic's concessions enough that their consumption engenders more consumption — something about the concessions brings the customers back again and again as their membership matures.

In light of this information, management will win by optimizing its concessions portfolio, delivery and marketing to defensively retain these big-spending customers.  It could offer concessions popular among older consumers, consider movie-themed product tie-ins in light of the segments' love for cinema, and create on-site advertising about its concessions with testimonials from satisfied long-term members to incentivize new members to try concessions early in their membership. Management should not rule out the use of deeply discounted coupons to encourage new members to try the concessions right after joining. Although our initial regression on the full data set shows that `discount:yes` has a negative effect on concession sales, that result was not statistically significant. Further experimentation could prove that a coupon for the right product(s), with the right amount of discount, or delivered at a convenient moment (offered proactively at the point-of-sale versus by email or post) increases spending.

**Offensively**, management can entice new customers by digitally advertising to middle-aged or senior consumers who are known movie buffs on Facebook — a platform whose users skew older. Additionally, management can opt **not** to advertise to leads who "like" or follow popular shows that are available exclusively on Netflix, Hulu or other streaming platforms, assuming that if they like several of those shows, the customers may have subscriptions to multiple streaming platforms.



### Penalized Regression Analysis

One way to address multicollinearity (if we had detected it in our model) would be to use a penalized regression. 

Penalized regressions add a regularization parameter to their coefficients if two or more predictors appear to be multicollinear while the algorithm regresses all predictors against each other. In that case, the **regressions carefully add errors or bias to their coefficients, assuming the tweaks will decrease variance when the regression applied to future samples**.

Glmnet's application of the Lasso regression is a powerful penalized regression tool and an optimal choice for variable selection. In contrast with a Ridge regression, which can penalize or tweak coefficients without fully declaring them statistically irrelevant, **the Lasso regression can set irrelevant predictors to zero and extract meaning from any remaining predictors**, however subtle their influence.

As seen below in MovieMagic's case, the coefficients of a Lasso regression built on all 2,000 observations tell us that we should use all the variables available to us to build a model. 


```{r, warning=FALSE, message=FALSE}

outcome <- data$amount_spent
predictors <- data.matrix(data[,c(1:8)])

# Create a Lasso model on all 2,000 observations in the original data set
lasso_model <- cv.glmnet(x = predictors,
                         y = outcome, 
                         alpha = 1,
                         standardize = TRUE,
                         nfolds = 4,
                         type.measure = "default")


# The coefficients of a Lasso regression on our dataset.
(lassm1 <- coef(lasso_model, s="lambda.min", exact=FALSE))

```

None of the variables have been set to 0 (normally expressed as "." when printed by glmnet). This tells us that at that scale of observation **even MovieMagic's statistically insignificant variables have some power to predict `amount_spent`**, however small. Those predictors don't have the statistical power to disprove the null hypothesis, but Lasso's failure to eliminate them means that their magnitude and direction still add meaning to the model in light of their relationship to other predictors.


### Avoid Overfitting with Test/Train Cross-Validation

Using any predictive model risks developing a regression with a laser-precise fit to a research sample that performs poorly when used on a fresh sample from the population being studied. Analysts walk a tightrope between bias and variance — how much precision should be sacrificed in the interest of generalizability to future samples from the population?

One way to mitigate that risk is to simulate the transition from the training sample to a new sample from the population by pretending that a minority percentage of our observations **are** a new sample. We call that percentage of observations a "test," "validation" or "hold-out" set. The remaining observations are called the "train" set because they're used to train our algorithm.

We answer the question of how much precision to sacrifice in the interest of generalizibility by making our test set larger or smaller by percentage until we find the model with optimal RMSE and R-squared values.

In the case of MovieMagic, we will cross-validate our findings by comparing a **80% train / 20% test** and a **70% train / 30% test** set.


```{r, warning=FALSE, message=FALSE}

set.seed(1234)

# Create the 70/30 train and test sets
sample7 <- sample.split(data$amount_spent, SplitRatio = 0.7)
train7 <- subset(data, sample7 == TRUE)
test7 <- subset(data, sample7 == FALSE)

# Create the 80/20 train and test sets
sample8 <- sample.split(data$amount_spent, SplitRatio = 0.8)
train8 <- subset(data, sample8 == TRUE)
test8 <- subset(data, sample8 == FALSE)

```


As seen below, in the case of the 80/20 split, the information lost in the 20% of observations dedicated to the test set means that `job` and `education` lose their predictive power — Lasso has set their influence to zero.

After an additional 10% of information is lost in the 70/30 split, Lasso also eliminates `seen_alone`. Furthermore, `streaming` keeps the direction of its effect, but loses some of its magnitude, falling from -0.78 to -0.39. Discount also loses some of its magnitude, falling from -0.33 to -0.13.

Both sets of revised coefficients suggest that not all variables will add predictive power to our regression. We knew from their significance levels that many were too statistically insignificant to study as a potential lever of action for management, but now we know that two to three variables don't add any predictive power to our model. That said, none of the eliminated variables included our statistically significant ones — the significant ones will probably still be the main levels of action for management — it's just a question of how large their effect will be.


```{r, warning=FALSE, message=FALSE}

# Create a Lasso regression on the 80/20 training set
lasso_model8 <- cv.glmnet(x = data.matrix(train8[,c(1:8)]),
                         y = train8$amount_spent, 
                         alpha = 1,
                         standardize = TRUE,
                         nfolds = 4,
                         type.measure = "default")


# Lasso coefficients of 80% training set
(lass8coef <- coef(lasso_model8, s="lambda.min", exact=FALSE))


# Create a Lasso regression on the 70/30 training set
lasso_model7 <- cv.glmnet(x = data.matrix(train7[,c(1:8)]),
                         y = train7$amount_spent, 
                         alpha = 1,
                         standardize = TRUE,
                         nfolds = 4,
                         type.measure = "default")


# Lasso coefficients of 70% training set
(lass7coef <- coef(lasso_model7, s="lambda.min", exact=FALSE))

```


Comparing the RSME, R-squared and MAE values performance of the two models below tells us which of the two splits best straddles bias and variance. The 80/20 split registers lower RMSE and MAE scores than the 70/30 split. This means **the 80/20 model is likely to perform better on future data sets**, even though it explains less variance within its test data compared to the 70/30 model, as evidenced by its slightly lower R-squared score.

 <!-- Chris and Bryan — this is where I got the interpretation above. It feels risky to use Stack Exchange as a source, but this helped me understand the results a little better than the professor's notes. https://datascience.stackexchange.com/questions/100605/rmse-vs-r-squared -->


```{r, warning=FALSE, message=FALSE}

# Create a Lasso model based on the 70/30 training set
model7 <- train(amount_spent ~ ., data = train7, method = "lasso", na.action=na.exclude)
predictions7 <-predict(model7, newdata=test7)

# Create a Lasso model based on the 80/20 training set
model8 <- train(amount_spent ~ ., data = train8, method = "lasso", na.action=na.exclude)
predictions8 <-predict(model8, newdata=test8)


# 70/30 split - RMSE, Rsquared, and MAE values
postResample(predictions7, test7$amount_spent)

# 80/20 split - RMSE, Rsquared, and MAE values
postResample(predictions8, test8$amount_spent)


```

**Text Analysis**

Question 6
MovieMagic wants to visualize the reviews through a wordcloud and wants to find
out which words are used most commonly in the reviews that customers write for
MovieMagic. Create 2 wordclouds - one for reviews that received 3, 4, or 5 star
ratings and another with reviews that received 1 or 2 stars ratings. Knowing the
prominent words in each of the wordclouds, what strategies can be developed in
messaging customers? Would the strategies differ?

Answer: 
"The strategies will differ greatly because the negative group is damage control messaging and the 
positive group is reminding them of why they loved going to the movie.  

Positive Reviews
The three most common words are Great, Movie, and Food.  Based on the top three most common words 
customers enjoyed the movies and food that was offered.  A few strategies that we would suggest 
focusing on are. Communication around new movies coming out and seasonal concession treats with images. 
Ideally if name and card information could be tied to what they purchased at the concession stand maybe 
a bogo could be offered to this group.  We would also like to conduct additional analysis to see what 
messaging is more effective i.e. new movie + concession bogo, new movie, new movie + discounted popcorn 
etc.  We would want to get this dialed in to see which is more effective.

Negative Reviews
The three most common words are Hour, Food, and Like.  Based on the word cloud the service was slow 
and took around an hour to get their food.  The negative reviews sound like they need internal strategies 
more than external ones.  Perhaps the theater concessions are under staffed, poorly organized, or has 
inefficient processes.  This could be focus area for the theaters manager to improve for their customers.
A time study could be completed on various nights to see the length of time it takes for people to get 
their food.  Once that number has been improved messaging to this group could be around the improvements 
in the speed of service. "

```{r, warning=FALSE, message=FALSE}

reviews <- read.csv(url("http://data.mishra.us/files/project_reviews.csv"))

#Positive Word Cloud

Positive_Reviews <- filter(reviews,star >= 3)

Review_corpus_p <- VCorpus(VectorSource(Positive_Reviews$text))

Review_corpus_p <- tm_map(Review_corpus_p, content_transformer(tolower)) # covert all to lower case else same word as lower and uppercase will classified as different
Review_corpus_p <- tm_map(Review_corpus_p, removeWords, stopwords(kind="en")) # remove stop words
func_Space <- content_transformer(function(x, pattern) gsub(pattern, " ", x)) # a function to clean /,@,\\,|
Review_corpus_p <- tm_map(Review_corpus_p, func_Space, "/|@|\\|")
Review_corpus_p <- tm_map(Review_corpus_p, stripWhitespace) # remove white space
Review_corpus_p <- tm_map(Review_corpus_p, removeNumbers) # remove numeric values
Review_corpus_p <- tm_map(Review_corpus_p, removePunctuation) # remove punctuations

dtm_review <- TermDocumentMatrix(Review_corpus_p)

m <- as.matrix(dtm_review)
v <- sort(rowSums(m),decreasing=TRUE)
review_final <- data.frame(word = names(v),freq=v)

set.seed(1234)
wordcloud(words = review_final$word, freq = review_final$freq, min.freq = 2,
          max.words=50, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"),scale=c(3, 0.7))

##Negative Word Cloud

Negative_Reviews <- filter(reviews,star < 3)

Review_corpus_n <- VCorpus(VectorSource(Negative_Reviews$text))

Review_corpus_n <- tm_map(Review_corpus_n, content_transformer(tolower)) # covert all to lower case else same word as lower and uppercase will classified as different

Review_corpus_n <- tm_map(Review_corpus_n, removeWords, stopwords(kind="en")) # if we remove stopwords the wordcloud becomes sparse. 
# Run with and without stop words to see how word cloud changes

func_Space <- content_transformer(function(x, pattern) gsub(pattern, " ", x)) # a function to clean /,@,\\,|
Review_corpus_n <- tm_map(Review_corpus_n, func_Space, "/|@|\\|")
Review_corpus_n <- tm_map(Review_corpus_n, stripWhitespace) # remove white space
Review_corpus_n <- tm_map(Review_corpus_n, removeNumbers) # remove numbers
Review_corpus_n <- tm_map(Review_corpus_n, removePunctuation) # remove punctuations


dtm_review_n <- TermDocumentMatrix(Review_corpus_n)

m_n <- as.matrix(dtm_review_n )
v_n <- sort(rowSums(m_n),decreasing=TRUE)
review_final_n <- data.frame(word = names(v_n),freq=v_n)

set.seed(1234)
wordcloud(words = review_final_n$word, freq = review_final_n$freq, min.freq = 1,
          max.words=50, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"),scale=c(3, .5))
```

7. MovieMagic also wants to use topic modeling to find out whether the content in
the reviews could be categorized into specific topics. If you used LDA to create 3 topic groups (k = 3), MovieMagic wants you to use 
the words within the 3 topics to infer topic title.  Which term is the most relevant in each of the three topics and how would it inform your 
business strategy? Given the topics you inferred what strategies would you suggest are possible for MovieMagic if it wants to increase con-
cession sales. Would you recommend promotions or advertising or loyalty program; justify your choice of business strategy?

Answer

Topic 1 
Title: Concessions
Top Word: Food
Top 3 words: Food, Fun, Cinema
Strategy: We would create a loyalty program so that we could gain additional insight into our customer base.  Once we have a large enough sample, we would utilize a clustering technique to identify common characteristics across our most lucrative segments and then cater promotions and advertising to them. This loyalty card could tie to what they purchase at concessions and what movies they tend to see.

Topic 2 
Title: Experience
Top Word: Movie
Top 3 words: Movie, Great, Place

Strategy: I would utilize the information from the loyalty card program to segment which customers would want to watch what movie and then push adds to those people.  This is the first action we need our customers to take during the customer journey so ideally it will resort in concession stand sales. Our customers come for the experience and the movie so perhaps additional analysis could be done to see who they are sharing the experience with.  If it is a group of friends going maybe offer a discount for 6 or more people. If it is a date night maybe offer a date night package with two tickets, drinks, and popcorn.  A couple of these concepts could be tested to see what customers respond to.  If we can increase the average group size and the frequency of people going to the movies concessions should follow.  

Topic 3 
Title: Random Words
Top Word: Just
Top 3 words: Just, Like, Guest

Strategy: Nothing emerged out of this topic to act upon.  Perplexity for three topics was lower then two topics which means three topics was better for our LDA model.  However, although the perplexity score for three topics was better, I would have preferred to keep this at two topics since the third topic did not provide any real value.


```{r, warning=FALSE, message=FALSE}

## Topic model LDA 

reviews_LDA <- read.csv(url("http://data.mishra.us/files/project_reviews.csv"))

LDA_corpus <- VCorpus(VectorSource(reviews_LDA$text)) #create corpus

#Preprocessing

LDA_corpus <- tm_map(LDA_corpus, content_transformer(tolower)) # covert all to lower case else same word as lower and uppercase will classified as different
LDA_corpus <- tm_map(LDA_corpus, removeWords, stopwords(kind="en")) # remove stop words
func_Space <- content_transformer(function(x, pattern) gsub(pattern, " ", x)) # a function to clean /,@,\\,|
LDA_corpus <- tm_map(LDA_corpus, func_Space, "/|@|\\|")
LDA_corpus <- tm_map(LDA_corpus, stripWhitespace) # remove white space
LDA_corpus <- tm_map(LDA_corpus, removeNumbers) # remove numeric values
LDA_corpus <- tm_map(LDA_corpus, removePunctuation) # remove punctuation


LDA_dtm <- DocumentTermMatrix(LDA_corpus) #create a DTM


rowTotals <- apply(LDA_dtm , 1, sum) #sum of words
LDA_dtm   <- LDA_dtm [rowTotals> 0, ] # removed rows with no words 

set.seed(123)
lda_topic <- LDA(LDA_dtm, k = 3, method = "Gibbs", control = NULL) # 3 LDA topics
LDA_topic_model <- tidy(lda_topic, matrix = "beta") 

top_terms <- LDA_topic_model %>%
  group_by(topic) %>%
  top_n(10, beta) %>% # 10 terms
  ungroup() %>%
  arrange(topic, -beta)

top_terms %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip()


# perplexity calculation - change k = values
lda <- LDA(LDA_dtm, k = 2, control = NULL) 
perplexity(lda)

```
## Experimental Design

Yes, a causal experiment can be performed. We would propose a 2x3 A/B Test with Loyalty Membership as one dimension and which ad was previewed before the movie as the second dimension.  The 3 treatments for the ad would be 1) ad targeted using words from Group 1 LDA, 2) ad targeted using words from Group 2 LDA 3) no pre-movie ad.  Every movie ticket would have an included discount for $1 off concessions with a QR code which would be scanned and allow us to determine which pre-movie ad treatment they received. Use of the coupon qualifies you to be counted in the study.  The outcome variable would be the amount spent on concessions.  We would want to analyze the data to determine per transaction average, per showing proportion of people that made a concession purchase, per day aggregate total concession sales, as well as comparing the results of all transactions where a ticket was scanned.